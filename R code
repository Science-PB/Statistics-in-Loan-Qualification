#Load libraries
library(glmnet)
library(FSA)
library(tidyverse)
library(readxl)
library(plyr)
library(dplyr)
library(MASS)
library(caTools)
library(ROCR)
library(rpart)
library(rpart.plot)
library(rattle)
library(RColorBrewer)

#Load dataset
loan<-read.csv("loan_data_set.csv")
str(loan)

#Create Baseline Model
table(loan$Loan_Status)
422/614

#Shuffle dataset
set.seed(1)
shuffle <- sample(1:nrow(loan))
head(shuffle)
loan <- loan[shuffle, ]
head(loan)

#Clean dataset
clean_loan <- loan %>%
  mutate(Loan_Status = ifelse(Loan_Status == "N", 0, 1)) %>%
  na.omit()
clean_loan <- clean_loan[,-1]
glimpse(clean_loan)

#Split and set up train and test dataset
train_test_set <- function(data, size = 0.8, train = TRUE) {
  n_row = nrow(data)
  total_row = size * n_row
  train_sample <- 1: total_row
  if (train == TRUE) {
    return (data[train_sample, ])}
  else {return (data[-train_sample, ])}}

loan_train <- train_test_set(clean_loan, 0.8, train = TRUE)
loan_test <- train_test_set(clean_loan, 0.8, train = FALSE)

dim(loan_train)
dim(loan_test)

prop.table(table(loan_train$Loan_Status))
prop.table(table(loan_test$Loan_Status))

#Method 1: Logistic Regression Model
loan_log <- glm(Loan_Status~. , data = loan_train, family = binomial)
summary(loan_log)

#Predictions on training dataset
predict_train <- predict(loan_log, type='response')
summary(predict_train)
tapply(predict_train, loan_train$Loan_Status, mean)

#Confusion matrix for threshold of 0.5
table_train <- table(loan_train$Loan_Status, predict_train > 0.5)
table_train
accuracy_train <- sum(diag(table_train))/sum(table_train)
print(paste('Accuracy for train', accuracy_train))


#ROC Curve - choosing optimum threshold value
ROCRpred <- prediction(predict_train, loan_train$Loan_Status)

#Performance Function
ROCRperf <- performance(ROCRpred, "tpr", "fpr")

#Plot ROC curve
plot(ROCRperf, colorize=TRUE,
     print.cutoffs.at=seq(0,1,by=0.1),
     text.adj=c(-0.2, 1.7))

#Prediction on Test Set
predict_test <- predict(loan_log, type = "response",
                       newdata = loan_test)

table_test <- table(loan_test$Loan_Status, predict_test >= 0.4)
table_test
accuracy_test <- sum(diag(table_test))/sum(table_test)
print(paste('Accuracy for test', accuracy_test))

#Method 2: Decision Tree

#Clean the datasets (set factor)
loan_train_dt <- loan_train %>%
  mutate(Loan_Status = factor(Loan_Status, levels = c(0, 1), labels = c('Denied', 'Approved')))
loan_test_dt <- loan_test %>%
  mutate(Loan_Status = factor(Loan_Status, levels = c(0, 1), labels = c('Denied', 'Approved')))

#Construct the model
fit <- rpart(Loan_Status ~ ., data = loan_train_dt,
             method = "class")
fancyRpartPlot(fit)

#Predict using the model
predict_unseen <- predict(fit, loan_test_dt, type='class')
table_mat <- table(loan_test_dt$Loan_Status, predict_unseen)
table_mat

accuracy_test <- sum(diag(table_mat))/sum(table_mat)
print(paste('Accuracy for test', accuracy_test))

#Tune the model
accuracy_tune <- function(fit) {
  predict_unseen <- predict(fit, loan_test_dt, type = 'class')  
  table_mat <- table(loan_test_dt$Loan_Status, predict_unseen)
  accuracy_test <- sum(diag(table_mat)) / sum(table_mat)
  accuracy_test
}

#Change parameters in decision tree
control <- rpart.control(minsplit = 2,
                         minbucket = round(2/3),
                         maxdepth = 2,
                         cp = 0.01)

#Calculate accuracy of tuned fitted data
tune_fit <- rpart(Loan_Status~., data = loan_train_dt, method = 'class', control = control)
fancyRpartPlot(tune_fit)
accuracy_tune(tune_fit)

